{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import zipfile \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'gdrive/MyDrive/Dataset/AjeebDataSet' # Path to folder containing data\n",
    "\n",
    "shape_to_label = {'foot':np.array([1.,0.,0.]),'notfoot':np.array([0.,1.,0.]),'ok':np.array([0.,0.,1.])}\n",
    "arr_to_shape = {np.argmax(shape_to_label[x]):x for x in shape_to_label.keys()}\n",
    "\n",
    "imgData = list()\n",
    "labels = list()\n",
    "\n",
    "for dr in os.listdir(DATA_PATH):\n",
    "    if dr not in ['foot','notfoot']:\n",
    "        continue\n",
    "    print(dr)\n",
    "    lb = shape_to_label[dr]\n",
    "    i = 0\n",
    "    for pic in os.listdir(os.path.join(DATA_PATH,dr)):\n",
    "        path = os.path.join(DATA_PATH,dr+'/'+pic)\n",
    "        img = cv2.imread(path)\n",
    "        imgData.append([img,lb])\n",
    "        imgData.append([cv2.flip(img, 1),lb]) #horizontally flipped image\n",
    "        #imgData.append([cv2.resize(img[50:250,50:250],(300,300)),lb]) # zoom : crop in and resize\n",
    "        i+=3\n",
    "    print(i)\n",
    "\n",
    "np.random.shuffle(imgData)\n",
    "\n",
    "imgData,labels = zip(*imgData)\n",
    "\n",
    "imgData = np.array(imgData)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(input_shape=(300, 350,3), include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "base_model = Sequential()\n",
    "base_model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
    "base_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(bottom_model, num_of_classes):\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024, activation = 'relu')(top_model)\n",
    "    top_model = Dense(512, activation = 'relu')(top_model)\n",
    "    top_model = Dense(num_of_classes, activation = 'softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "num_of_classes = 2\n",
    "FC_Head = add_layer(model, num_of_classes)\n",
    "\n",
    "model = Model(inputs = model.input, outputs = FC_Head)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint('foot_detector1.h15',\n",
    "                            monitor = 'loss',\n",
    "                            mode = min,\n",
    "                            save_best_only = True,\n",
    "                            verbose = 1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'loss',\n",
    "                         min_delta = 0,\n",
    "                         patience = 3,\n",
    "                         verbose = 1,\n",
    "                         restore_best_weights = True)\n",
    "\n",
    "callbacks = [checkpoint, earlystop]\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'Adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "epochs = 6\n",
    "#batch_size = 1\n",
    "\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            epochs = epochs,\n",
    "            callbacks = callbacks)\n",
    "\n",
    "model.save_weights('resnet_detector1.h5')\n",
    "\n",
    "with open(\"resnet_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
